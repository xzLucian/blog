# LangChain Chains
## 1. Chainsçš„åŸºæœ¬ä½¿ç”¨
### 1.1 Chainçš„åŸºæœ¬æ¦‚å¿µ
Chainï¼šé“¾ï¼Œç”¨äºå°†å¤šä¸ªç»„ä»¶ï¼ˆæç¤ºæ¨¡æ¿ã€LLMæ¨¡å‹ã€è®°å¿†ã€å·¥å…·ç­‰ï¼‰è¿æ¥èµ·æ¥ï¼Œå½¢æˆå¯å¤ç”¨çš„ å·¥ä½œæµ ï¼Œå®Œæˆå¤æ‚çš„ä»»åŠ¡ã€‚
**Chainçš„æ ¸å¿ƒæ€æƒ³**æ˜¯é€šè¿‡ç»„åˆä¸åŒçš„æ¨¡å—åŒ–å•å…ƒï¼Œå®ç°æ¯”å•ä¸€ç»„ä»¶æ›´å¼ºå¤§çš„åŠŸèƒ½ã€‚æ¯”å¦‚ï¼š
- å°† **`LLM`** ä¸ **`Prompt Template`**ï¼ˆæç¤ºæ¨¡æ¿ï¼‰ç»“åˆ
- å°† **`LLM`** ä¸ **`è¾“å‡ºè§£æå™¨`** ç»“åˆ
- å°† **`LLM`** ä¸ **`å¤–éƒ¨æ•°æ®`** ç»“åˆï¼Œä¾‹å¦‚ç”¨äºé—®ç­”
- å°† **`LLM`** ä¸ **`é•¿æœŸè®°å¿†`** ç»“åˆï¼Œä¾‹å¦‚ç”¨äºèŠå¤©å†å²è®°å½•
- é€šè¿‡å°† **`ç¬¬ä¸€ä¸ªLLM`** çš„è¾“å‡ºä½œä¸º **`ç¬¬äºŒä¸ªLLM`** çš„è¾“å…¥ï¼Œ...ï¼Œå°†å¤šä¸ªLLMæŒ‰é¡ºåºç»“åˆåœ¨ä¸€èµ·
### 1.2 LCELåŠå…¶åŸºæœ¬æ„æˆ
ä½¿ç”¨LCELï¼Œå¯ä»¥æ„é€ å‡ºç»“æ„æœ€ç®€å•çš„Chainã€‚
LangChainè¡¨è¾¾å¼è¯­è¨€ï¼ˆLCELï¼ŒLangChain Expression Languageï¼‰æ˜¯ä¸€ç§å£°æ˜å¼æ–¹æ³•ï¼Œå¯ä»¥è½»æ¾åœ°
å°†å¤šä¸ªç»„ä»¶é“¾æ¥æˆ AI å·¥ä½œæµã€‚å®ƒé€šè¿‡PythonåŸç”Ÿæ“ä½œç¬¦ï¼ˆå¦‚ç®¡é“ç¬¦ | ï¼‰å°†ç»„ä»¶è¿æ¥æˆå¯æ‰§è¡Œæµç¨‹ï¼Œæ˜¾è‘—ç®€åŒ–äº†AIåº”ç”¨çš„å¼€å‘ã€‚

**LCELçš„åŸºæœ¬æ„æˆ**ï¼šæç¤ºï¼ˆPromptï¼‰+ æ¨¡å‹ï¼ˆModelï¼‰+ è¾“å‡ºè§£æå™¨ï¼ˆOutputParserï¼‰

```python
# åœ¨è¿™ä¸ªé“¾æ¡ä¸­ï¼Œç”¨æˆ·è¾“å…¥è¢«ä¼ é€’ç»™æç¤ºæ¨¡æ¿ï¼Œç„¶åæç¤ºæ¨¡æ¿çš„è¾“å‡ºè¢«ä¼ é€’ç»™æ¨¡å‹ï¼Œç„¶åæ¨¡å‹çš„è¾“å‡ºè¢«ä¼ é€’ç»™è¾“å‡ºè§£æå™¨ã€‚
chain = prompt | model | output_parser
chain.invoke({"input":"What's your name?"})
```
- **Prompt**ï¼šPrompt æ˜¯ä¸€ä¸ª BasePromptTemplateï¼Œè¿™æ„å‘³ç€å®ƒæ¥å—ä¸€ä¸ªæ¨¡æ¿å˜é‡çš„å­—å…¸å¹¶ç”Ÿæˆä¸€ä¸ª`PromptValue`ã€‚PromptValue å¯ä»¥ä¼ é€’ç»™LLMï¼ˆå®ƒä»¥å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥ï¼‰æˆ– ChatModelï¼ˆå®ƒä»¥æ¶ˆæ¯åºåˆ—ä½œä¸ºè¾“å…¥ï¼‰ã€‚
- **Model**ï¼šå°†PromptValueä¼ é€’ç»™modelã€‚å¦‚æœæˆ‘ä»¬çš„ modelæ˜¯ä¸€ä¸ªChatModelï¼Œè¿™æ„å‘³ç€å®ƒ
å°†è¾“å‡ºä¸€ä¸ª`BaseMessage`ã€‚
- **OutputParser**ï¼šå°†modelçš„è¾“å‡ºä¼ é€’ç»™ output_parserï¼Œå®ƒæ˜¯ä¸€ä¸ª BaseOutputParserï¼Œæ„å‘³ç€å®ƒå¯ä»¥æ¥å—å­—ç¬¦ä¸²æˆ– BaseMessage ä½œä¸ºè¾“å…¥ã€‚
- **chain**ï¼šæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ | è¿ç®—ç¬¦è½»æ¾åˆ›å»ºè¿™Chainã€‚|è¿ç®—ç¬¦åœ¨LangChainä¸­ç”¨äºå°†ä¸¤ä¸ªå…ƒç´ ç»„åˆåœ¨ä¸€èµ·ã€‚
- **invoke**ï¼šæ‰€æœ‰LCELå¯¹è±¡éƒ½å®ç°äº† **`Runnable`** åè®®ï¼Œä¿è¯ä¸€è‡´çš„è°ƒç”¨æ–¹å¼ï¼ˆ **invoke / batch / stream** ï¼‰
> | ç¬¦å·ç±»ä¼¼äºshellâ¾¥â¾¯ç®¡é“æ“ä½œç¬¦ï¼Œå®ƒå°†ä¸åŒçš„ç»„ä»¶é“¾æ¥åœ¨â¼€èµ·ï¼Œå°†å‰â¼€ä¸ªç»„ä»¶çš„è¾“å‡ºä½œä¸ºä¸‹â¼€ä¸ªç»„ä»¶çš„è¾“â¼Šï¼Œè¿™å°±å½¢æˆäº†â¼€ä¸ª AI â¼¯ä½œæµã€‚

### 1.3 Runnable
Runnableæ˜¯LangChainå®šä¹‰çš„ä¸€ä¸ªæŠ½è±¡æ¥å£ï¼ˆProtocolï¼‰ï¼Œå®ƒ`å¼ºåˆ¶è¦æ±‚`æ‰€æœ‰LCELç»„ä»¶å®ç°ä¸€ç»„æ ‡å‡†æ–¹æ³•ï¼š
```python
class Runnable(Protocol):
    def invoke(self, input: Any) -> Any: ... # å•è¾“å…¥å•è¾“å‡º
    def batch(self, inputs: List[Any]) -> List[Any]: ... # æ‰¹é‡å¤„ç†
    def stream(self, input: Any) -> Iterator[Any]: ... # æµå¼è¾“å‡º
    # è¿˜æœ‰å…¶ä»–æ–¹æ³•å¦‚ ainvokeï¼ˆå¼‚æ­¥ï¼‰ç­‰...
```
ä»»ä½•å®ç°äº†è¿™äº›æ–¹æ³•çš„å¯¹è±¡éƒ½è¢«è§†ä¸ºLCELå…¼å®¹ç»„ä»¶ã€‚æ¯”å¦‚ï¼šèŠå¤©æ¨¡å‹ã€æç¤ºè¯æ¨¡æ¿ã€è¾“å‡ºè§£æå™¨ã€æ£€ç´¢å™¨ã€ä»£ç†(æ™ºèƒ½ä½“)ç­‰ã€‚
æ¯ä¸ª LCEL å¯¹è±¡éƒ½å®ç°äº† Runnable æ¥å£ï¼Œè¯¥æ¥å£å®šä¹‰äº†ä¸€ç»„å…¬å…±çš„è°ƒç”¨æ–¹æ³•ã€‚è¿™ä½¿å¾— LCEL å¯¹è±¡é“¾ä¹Ÿè‡ªåŠ¨æ”¯æŒè¿™äº›è°ƒç”¨æˆä¸ºå¯èƒ½ã€‚
**â“ ä¸ºä»€ä¹ˆéœ€è¦ç»Ÿä¸€è°ƒç”¨æ–¹å¼ï¼Ÿ**
**ä¼ ç»Ÿé—®é¢˜**
å‡è®¾æ²¡æœ‰ç»Ÿä¸€åè®®ï¼š
- æç¤ºè¯æ¸²æŸ“ç”¨ `.format()`
- æ¨¡å‹è°ƒç”¨ç”¨ `.generate()`
- è§£æå™¨è§£æç”¨ `.parse()`
- å·¥å…·è°ƒç”¨ç”¨ `.run()`
ä»£ç ä¼šå˜æˆï¼š
```python
prompt_text = prompt.format(topic="çŒ«") # æ–¹æ³•1
model_out = model.generate(prompt_text) # æ–¹æ³•2
result = parser.parse(model_out) # æ–¹æ³•3
```
**ç—›ç‚¹ï¼š**
æ¯ä¸ªç»„ä»¶è°ƒç”¨æ–¹å¼ä¸åŒï¼Œç»„åˆæ—¶éœ€è¦æ‰‹åŠ¨é€‚é…ã€‚

**LCELè§£å†³æ–¹æ¡ˆ**

é€šè¿‡ Runnable åè®®ç»Ÿä¸€ï¼š
```python
#ï¼ˆåˆ†æ­¥è°ƒç”¨ï¼‰
prompt_text = prompt.invoke({"topic": "çŒ«"}) # æ–¹æ³•1
model_out = model.invoke(prompt_text) # æ–¹æ³•2
result = parser.invoke(model_out) # æ–¹æ³•3
#ï¼ˆLCELç®¡é“å¼ï¼‰
chain = prompt | model | parser # ç”¨ç®¡é“ç¬¦ç»„åˆ
result = chain.invoke({"topic": "çŒ«"}) # æ‰€æœ‰ç»„ä»¶ç»Ÿä¸€ç”¨invoke
```
- **ä¸€è‡´æ€§**ï¼šæ— è®ºç»„ä»¶çš„åŠŸèƒ½å¤šå¤æ‚ï¼ˆæ¨¡å‹/æç¤ºè¯/å·¥å…·ï¼‰ï¼Œè°ƒç”¨æ–¹å¼å®Œå…¨ç›¸åŒ
- **ç»„åˆæ€§**ï¼šç®¡é“æ“ä½œç¬¦ | èƒŒåè‡ªåŠ¨å¤„ç†ç±»å‹åŒ¹é…å’Œä¸­é—´ç»“æœä¼ é€’

### 1.4 ä½¿ç”¨ä¸¾ä¾‹
***ä¸¾ä¾‹1***
```python
from dotenv import load_dotenv
from langchain_core.output_parsers import StrOutputParser

load_dotenv()
chat_model = ChatOpenAI(model="gpt-4o-mini")

prompt_template = PromptTemplate.from_template(template = "ç»™æˆ‘è®²ä¸€ä¸ªå…³äº{topic}è¯é¢˜çš„ç®€çŸ­ç¬‘è¯")
parser = StrOutputParser()
# æ„å»ºé“¾å¼è°ƒç”¨ï¼ˆLCELè¯­æ³•ï¼‰
chain = prompt_template | chat_model | parser
out_put = chain.invoke({"topic": "ice cream"})
print(out_put)
print(type(out_put))
```
```
ä¸ºä»€ä¹ˆå†°æ·‡æ·‹æ€»æ˜¯å¾ˆå¿«ä¹ï¼Ÿ
å› ä¸ºå®ƒçŸ¥é“â¾ƒâ¼°æ˜¯ä¸ªâ€œç”œâ€â»†â¾Šï¼ğŸ¦ğŸ˜„
<class 'str'>
```
## 2. ä¼ ç»ŸChainçš„ä½¿ç”¨
### 2.1 åŸºç¡€é“¾ï¼šLLMChain
#### 2.1.1 ä½¿ç”¨è¯´æ˜
LCELä¹‹å‰ï¼Œæœ€åŸºç¡€ä¹Ÿæœ€å¸¸è§çš„é“¾ç±»å‹æ˜¯LLMChainã€‚
**è¿™ä¸ªé“¾è‡³å°‘åŒ…æ‹¬ä¸€ä¸ªæç¤ºè¯æ¨¡æ¿ï¼ˆPromptTemplateï¼‰ï¼Œä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼ˆLLM æˆ–èŠå¤©æ¨¡å‹ï¼‰ã€‚**
::: warning
æ³¨æ„ï¼šLLMChain was deprecated in LangChain 0.1.17 and will be removed in 1.0 Use **Prompt | llm** instead
:::
**ç‰¹ç‚¹ï¼š**
- ç”¨äº`å•æ¬¡é—®ç­”`ï¼Œè¾“å…¥ä¸€ä¸ª Promptï¼Œè¾“å‡º LLM çš„å“åº”ã€‚
- é€‚åˆ`æ— ä¸Šä¸‹æ–‡`çš„ç®€å•ä»»åŠ¡ï¼ˆå¦‚ç¿»è¯‘ã€æ‘˜è¦ã€åˆ†ç±»ç­‰ï¼‰ã€‚
- `æ— è®°å¿†`ï¼šæ— æ³•è‡ªåŠ¨ç»´æŠ¤èŠå¤©å†å²

#### 2.1.2 ä¸»è¦æ­¥éª¤
**1ã€é…ç½®ä»»åŠ¡é“¾**ï¼šä½¿ç”¨LLMChainç±»å°†ä»»åŠ¡ä¸æç¤ºè¯ç»“åˆï¼Œå½¢æˆå®Œæ•´çš„ä»»åŠ¡é“¾ã€‚
```python
chain = LLMChain(llm = llm, prompt = prompt_template)
```
**2ã€æ‰§è¡Œä»»åŠ¡é“¾**ï¼šä½¿ç”¨invoke()ç­‰æ–¹æ³•æ‰§è¡Œä»»åŠ¡é“¾ï¼Œå¹¶è·å–ç”Ÿæˆç»“æœã€‚å¯ä»¥æ ¹æ®éœ€è¦å¯¹è¾“å‡ºè¿›è¡Œå¤„ç†å’Œå±•ç¤ºã€‚
```python
result = chain.invoke(...)
print(result)
```
***ä¸¾ä¾‹ï¼š***
```python
# 1.å¯¼å…¥ç›¸å…³åŒ…
from langchain.chains.llm import LLMChain
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
# 2.å®šä¹‰æç¤ºè¯æ¨¡ç‰ˆå¯¹è±¡
chat_template = ChatPromptTemplate.from_messages(
  [
    ("system","ä½ æ˜¯ä¸€ä½{area}é¢†åŸŸå…·å¤‡ä¸°å¯Œç»éªŒçš„é«˜ç«¯æŠ€æœ¯äººæ‰"),
    ("human", "ç»™æˆ‘è®²ä¸€ä¸ª {adjective} ç¬‘è¯"),
  ]
)
# 3.å®šä¹‰æ¨¡å‹
llm = ChatOpenAI(model="gpt-4o-mini")
# 4.å®šä¹‰LLMChain
llm_chain = LLMChain(llm=llm, prompt=chat_template, verbose=True)

# 5.è°ƒç”¨LLMChain
response = llm_chain.invoke({"area":"äº’è”ç½‘","adjective":"ä¸Šç­çš„"})
print(response)
```
> \> Entering new LLMChain chain...
Prompt after formatting:
System: ä½ æ˜¯ä¸€ä½äº’è”ç½‘é¢†åŸŸå…·å¤‡ä¸°å¯Œç»éªŒçš„é«˜ç«¯æŠ€æœ¯äººæ‰
Human: ç»™æˆ‘è®²ä¸€ä¸ª ä¸Šç­çš„ ç¬‘è¯

> \> Finished chain.
{'area': 'äº’è”ç½‘', 'adjective': 'ä¸Šç­çš„', 'text': 'å½“ç„¶å¯ä»¥ï¼è¿™æ˜¯ä¸€ä¸ªä¸Šç­çš„ç¬‘è¯ï¼š\n\næœ‰ä¸€å¤©ï¼Œè€æ¿å¯¹å‘˜å·¥è¯´ï¼šâ€œä½ çŸ¥é“ä¸ºä»€ä¹ˆæˆ‘æ€»æ˜¯æŠŠä½ çš„å·¥ä½œæ¨è¿Ÿå—ï¼Ÿâ€\n\nå‘˜å·¥å¥½å¥‡åœ°é—®ï¼šâ€œä¸ºä»€ä¹ˆå‘¢ï¼Ÿâ€\n\nè€æ¿å¾®ç¬‘ç€å›ç­”ï¼šâ€œå› ä¸ºæˆ‘æƒ³è®©ä½ ä»¬çš„å·¥ä½œä¿æŒæ–°é²œæ„Ÿï¼Œæ¯æ¬¡éƒ½ç»™ä½ ä»¬ä¸€ä¸ªæ–°çš„æˆªæ­¢æ—¥æœŸï¼Œè¿™æ ·ä½ ä»¬å°±èƒ½æœ‰æ›´å¤šçš„â€˜æœŸå¾…â€™ï¼â€\n\nå‘˜å·¥æ— å¥ˆåœ°è¯´ï¼šâ€œé‚£æˆ‘å¸Œæœ›èƒ½æŠŠâ€˜æœŸå¾…â€™æ¢æˆè–ªæ°´ï¼â€\n\nå¸Œæœ›è¿™ä¸ªç¬‘è¯èƒ½è®©ä½ ç¬‘ä¸€ç¬‘ï¼'}

### 2.2 é¡ºåºé“¾ä¹‹SimpleSequentialChain
é¡ºåºé“¾ï¼ˆSequentialChainï¼‰å…è®¸å°†å¤šä¸ªé“¾é¡ºåºè¿æ¥èµ·æ¥ï¼Œæ¯ä¸ªChainçš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªChainçš„è¾“å…¥ï¼Œ
å½¢æˆç‰¹å®šåœºæ™¯çš„æµæ°´çº¿ï¼ˆPipelineï¼‰ã€‚

**é¡ºåºé“¾æœ‰ä¸¤ç§ç±»å‹ï¼š**
- å•ä¸ªè¾“å…¥/è¾“å‡ºï¼šå¯¹åº”ç€ SimpleSequentialChain
- å¤šä¸ªè¾“å…¥/è¾“å‡ºï¼šå¯¹åº”ç€ï¼šSequentialChain
#### 2.2.1 è¯´æ˜
SimpleSequentialChainï¼šæœ€ç®€å•çš„é¡ºåºé“¾ï¼Œå¤šä¸ªé“¾`ä¸²è”æ‰§è¡Œ`ï¼Œæ¯ä¸ªæ­¥éª¤éƒ½æœ‰`å•ä¸€`çš„è¾“å…¥å’Œè¾“å‡ºï¼Œä¸€ä¸ªæ­¥éª¤çš„è¾“å‡ºå°±æ˜¯ä¸‹ä¸€ä¸ªæ­¥éª¤çš„è¾“å…¥ï¼Œæ— éœ€æ‰‹åŠ¨æ˜ å°„ã€‚
![alt text](/public/langchain/chain/1.png)
#### 2.2.2 ä½¿ç”¨ä¸¾ä¾‹
***ä¸¾ä¾‹:***
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import LLMChain
# å¯¼å…¥SimpleSequentialChain
from langchain.chains import SimpleSequentialChain
chainA_template = ChatPromptTemplate.from_messages(
  [
    ("system", "ä½ æ˜¯ä¸€ä½ç²¾é€šå„é¢†åŸŸçŸ¥è¯†çš„çŸ¥åæ•™æˆ"),
    ("human", "è¯·ä½ å°½å¯èƒ½è¯¦ç»†çš„è§£é‡Šä¸€ä¸‹ï¼š{knowledge}"),
  ]
)
chainA_chains = LLMChain(llm=llm,prompt=chainA_template,verbose=True)
chainA_chains.invoke({"knowledge":"ä»€ä¹ˆæ˜¯LangChainï¼Ÿ"})

chainB_template = ChatPromptTemplate.from_messages(
  [
    ("system", "ä½ éå¸¸å–„äºæå–æ–‡æœ¬ä¸­çš„é‡è¦ä¿¡æ¯ï¼Œå¹¶åšå‡ºç®€çŸ­çš„æ€»ç»“"),
    ("human", "è¿™æ˜¯é’ˆå¯¹ä¸€ä¸ªæé—®çš„å®Œæ•´çš„è§£é‡Šè¯´æ˜å†…å®¹ï¼š{description}"),
    ("human", "è¯·ä½ æ ¹æ®ä¸Šè¿°è¯´æ˜ï¼Œå°½å¯èƒ½ç®€çŸ­çš„è¾“å‡ºé‡è¦çš„ç»“è®ºï¼Œè¯·æ§åˆ¶åœ¨20ä¸ªå­—ä»¥"),
  ]
)
chainB_chains = LLMChain(llm=llm,prompt=chainB_template,verbose=True)
# åœ¨chainså‚æ•°ä¸­ï¼ŒæŒ‰é¡ºåºä¼ å…¥LLMChain A å’ŒLLMChain B
full_chain = SimpleSequentialChain(chains=[chainA_chains, chainB_chains], verbose=True)
full_chain.invoke({"input":"ä»€ä¹ˆæ˜¯langChainï¼Ÿ"})
```
```
...
{'input': 'ä»€ä¹ˆæ˜¯langChainï¼Ÿ', 'output': 'LangChainæ˜¯æ„å»ºNLPåº”â½¤çš„çµæ´»æ¡†æ¶ï¼Œç®€åŒ–ä¸è¯­â¾”æ¨¡å‹çš„äº’åŠ¨ã€‚'}
```
åœ¨è¿™ä¸ªè¿‡ç¨‹ä¸­ï¼Œå› ä¸º`SimpleSequentialChain`å®šä¹‰çš„æ˜¯é¡ºåºé“¾ï¼Œæ‰€ä»¥åœ¨`chains`å‚æ•°ä¸­ä¼ é€’çš„åˆ—è¡¨è¦æŒ‰ç…§é¡ºåºæ¥è¿›è¡Œä¼ å…¥ï¼Œå³LLMChain A è¦åœ¨LLMChain Bä¹‹å‰ã€‚åŒæ—¶ï¼Œåœ¨è°ƒç”¨æ—¶ï¼Œä¸å†ä½¿ç”¨LLMChain Aä¸­å®šä¹‰çš„`{knowledge}`å‚æ•°ï¼Œä¹Ÿä¸æ˜¯LLMChainBä¸­å®šä¹‰çš„`{description}`å‚æ•°ï¼Œè€Œæ˜¯è¦ä½¿ç”¨`input`è¿›è¡Œå˜é‡çš„ä¼ é€’ã€‚
```python
class SimpleSequentialChain(Chain):
    """Simple chain where the outputs of one step feed directly into next."""
    chains: List[Chain]
    strip_outputs: bool = False
    input_key: str = "input" #: :meta private:
    output_key: str = "output" #: :meta private:
```
### 2.3 é¡ºåºé“¾ä¹‹ SequentialChain
#### 2.3.1 è¯´æ˜
SequentialChainï¼šæ›´é€šç”¨çš„é¡ºåºé“¾ï¼Œå…·ä½“æ¥è¯´ï¼š
- **`å¤šå˜é‡æ”¯æŒ`**ï¼šå…è®¸ä¸åŒå­é“¾æœ‰ç‹¬ç«‹çš„è¾“å…¥/è¾“å‡ºå˜é‡ã€‚
- **`çµæ´»æ˜ å°„`**ï¼šéœ€ æ˜¾å¼å®šä¹‰ å˜é‡å¦‚ä½•ä»ä¸€ä¸ªé“¾ä¼ é€’åˆ°ä¸‹ä¸€ä¸ªé“¾ã€‚å³ç²¾å‡†åœ°å‘½åè¾“å…¥å…³é”®å­—å’Œè¾“å‡ºå…³é”®å­—ï¼Œæ¥æ˜ç¡®é“¾ä¹‹é—´çš„å…³ç³»ã€‚
- **`å¤æ‚æµç¨‹æ§åˆ¶`**ï¼šæ”¯æŒåˆ†æ”¯ã€æ¡ä»¶é€»è¾‘ï¼ˆåˆ†åˆ«é€šè¿‡ input_variables å’Œ output_variables é…ç½®è¾“å…¥å’Œè¾“å‡ºï¼‰ã€‚
![alt text](/public/langchain/chain/2.png)
#### 2.3.2 ä½¿ç”¨ä¸¾ä¾‹
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain.chains import SequentialChain
from langchain_openai import ChatOpenAI
from langchain.chains import LLMChain
from openai import OpenAI
import os
# åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹
llm = ChatOpenAI(model="gpt-4o-mini")
schainA_template = ChatPromptTemplate.from_messages(
  [
    ("system", "ä½ æ˜¯ä¸€ä½ç²¾é€šå„é¢†åŸŸçŸ¥è¯†çš„çŸ¥åæ•™æˆ"),
    ("human", "è¯·ä½ å…ˆå°½å¯èƒ½è¯¦ç»†çš„è§£é‡Šä¸€ä¸‹ï¼š{knowledge}ï¼Œå¹¶ä¸”{action}")
  ]
)
schainA_chains = LLMChain(llm=llm,prompt=schainA_template,verbose=True,output_key="schainA_chains_key")
# schainA_chains.invoke({
# "knowledge": "ä¸­å›½çš„ç¯®çƒæ€ä¹ˆæ ·ï¼Ÿ",
# "action": "ä¸¾ä¸€ä¸ªå®é™…çš„ä¾‹å­"
# }
# )
schainB_template = ChatPromptTemplate.from_messages(
  [
    ("system", "ä½ éå¸¸å–„äºæå–æ–‡æœ¬ä¸­çš„é‡è¦ä¿¡æ¯ï¼Œå¹¶åšå‡ºç®€çŸ­çš„æ€»ç»“"),
    ("human", "è¿™æ˜¯é’ˆå¯¹ä¸€ä¸ªæé—®å®Œæ•´çš„è§£é‡Šè¯´æ˜å†…å®¹ï¼š{schainA_chains_key}"),
    ("human", "è¯·ä½ æ ¹æ®ä¸Šè¿°è¯´æ˜ï¼Œå°½å¯èƒ½ç®€çŸ­çš„è¾“å‡ºé‡è¦çš„ç»“è®ºï¼Œè¯·æ§åˆ¶åœ¨100ä¸ªå­—ä»¥"),
  ]
)
schainB_chains = LLMChain(llm=llm,prompt=schainB_template,verbose=True,output_key='schainB_chains_key')

Seq_chain = SequentialChain(
  chains=[schainA_chains, schainB_chains],
  input_variables=["knowledge", "action"],
  output_variables=["schainA_chains_key","schainB_chains_key"],
  verbose=True
)
response = Seq_chain.invoke(
  {
    "knowledge":"ä¸­å›½è¶³çƒä¸ºä»€ä¹ˆè¸¢å¾—çƒ‚",
    "action":"ä¸¾ä¸€ä¸ªå®é™…çš„ä¾‹å­"
  }
)
print(response)
```
è¿˜å¯ä»¥å•ç‹¬è¾“å‡ºï¼š
```python
print(response["schainA_chains_key"])
print(response["schainB_chains_key"])
```
#### 2.3.3 é¡ºåºé“¾ä½¿ç”¨åœºæ™¯
**åœºæ™¯**ï¼šå¤šæ•°æ®æºå¤„ç†

ä¸¾ä¾‹ï¼šæ ¹æ®äº§å“å
> 1. æŸ¥è¯¢æ•°æ®åº“è·å–ä»·æ ¼
> 2. ç”Ÿæˆä¿ƒé”€æ–‡æ¡ˆ

**ä½¿ç”¨ SimpleSequentialChainï¼ˆä¼šå¤±è´¥ï¼‰**
```
# å‡è®¾é“¾1è¿”å› {"price": 100}, é“¾2éœ€è¦ {product: "xx", price: xx}
# ç»“æ„ä¸åŒ¹é…ï¼Œæ— æ³•è‡ªåŠ¨ä¼ é€’ï¼
```

**ä½¿ç”¨ SequentialChainï¼ˆæ­£ç¡®æ–¹å¼ï¼‰**
```python
from langchain.chains import SequentialChain
# åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹
llm = ChatOpenAI(model="gpt-4o-mini")
# ç¬¬1ç¯èŠ‚ï¼š
query_chain = LLMChain(
  llm=llm,
  prompt=PromptTemplate.from_template(template="è¯·æ¨¡æ‹ŸæŸ¥è¯¢{product}çš„å¸‚åœºä»·æ ¼ï¼Œç›´æ¥è¿”å›ä¸€ä¸ªåˆç†çš„ä»·æ ¼æ•°å­—ï¼ˆå¦‚6999ï¼‰ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—æˆ–ä»£ç "),verbose=True,
  output_key="price")
# ç¬¬2ç¯èŠ‚ï¼š
promo_chain = LLMChain(
  llm=llm,
  prompt=PromptTemplate.from_template(template="ä¸º{product}ï¼ˆå”®ä»·ï¼š{price}å…ƒï¼‰åˆ›ä½œä¸€ç¯‡50å­—ä»¥å†…çš„ä¿ƒé”€æ–‡æ¡ˆï¼Œè¦æ±‚çªå‡ºäº§å“å–ç‚¹"),verbose=True,output_key="promo_text"
)
sequential_chain = SequentialChain(
  chains=[query_chain, promo_chain],
  verbose=True,input_variables=["product"], # åˆå§‹è¾“å…¥
  output_variables=["price", "promo_text"], # è¾“å‡ºä»·æ ¼å’Œæ–‡æ¡ˆ
)
result = sequential_chain.invoke({"product": "iPhone16"})
print(result)
# print(result["price"]
# print(result["promo_text"]
```
```
{
  'product': 'iPhone16',
  'price': '6999',
  'promo_text': 'å…¨æ–°iPhone 16ï¼Œ6999å…ƒï¼Œä½“éªŒè¶…â¾¼æ¸…å½±åƒä¸å¼ºåŠ²æ€§èƒ½ï¼ŒA17èŠ¯â½šåŠ©ä½ ç•…äº«æµç•…æ“ä½œã€‚â½†ä¸ä¼¦â½çš„ç»­èˆªä¸åˆ›æ–°è®¾è®¡ï¼ŒæœŸå¾…ä½ çš„æ¯â¼€æ¬¡å‘ç°ï¼Œå¼€å¯æœªæ¥æ™ºèƒ½â½£æ´»ï¼å°½å¿«æŠ¢è´­ï¼Œåé¢æœ‰é™ï¼'
}
```

### 2.4 æ•°å­¦é“¾LLMMathChain(äº†è§£)
LLMMathChainå°†ç”¨æˆ·é—®é¢˜è½¬æ¢ä¸ºæ•°å­¦é—®é¢˜ï¼Œç„¶åå°†æ•°å­¦é—®é¢˜è½¬æ¢ä¸ºå¯ä»¥ä½¿ç”¨**Python**çš„**numexpr**åº“æ‰§è¡Œçš„è¡¨è¾¾å¼ã€‚ä½¿ç”¨è¿è¡Œæ­¤ä»£ç çš„è¾“å‡ºæ¥å›ç­”é—®é¢˜ã€‚

ä½¿ç”¨LLMMathChainï¼Œéœ€è¦å®‰è£…numexpråº“
> pip install numexpr
```python
from langchain.chains import LLMMathChain
import os
import dotenv
from langchain_openai import ChatOpenAI
from langchain.chains import LLMChain

dotenv.load_dotenv()
os.environ['OPENAI_API_KEY'] = os.getenv("OPENAI_API_KEY1")
os.environ['OPENAI_BASE_URL'] = os.getenv("OPENAI_BASE_URL")
# åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹
llm = ChatOpenAI(model="gpt-4o-mini")
# åˆ›å»ºé“¾
llm_math = LLMMathChain.from_llm(llm)
# æ‰§è¡Œé“¾
res = llm_math.invoke("10 ** 3 + 100çš„ç»“æœæ˜¯å¤šå°‘ï¼Ÿ")
print(res)
```
```
{'question': '10 ** 3 + 100çš„ç»“æœæ˜¯å¤šå°‘ï¼Ÿ', 'answer': 'Answer: 1100'}
```
### 2.5 è·¯ç”±é“¾ RouterChain (äº†è§£)
è·¯ç”±é“¾ï¼ˆRouterChainï¼‰ç”¨äºåˆ›å»ºå¯ä»¥ åŠ¨æ€é€‰æ‹©ä¸‹ä¸€æ¡é“¾ çš„é“¾ã€‚å¯ä»¥è‡ªåŠ¨åˆ†æç”¨æˆ·çš„éœ€æ±‚ï¼Œç„¶åå¼•å¯¼åˆ°æœ€é€‚åˆçš„é“¾ä¸­æ‰§è¡Œï¼Œè·å–å“åº”å¹¶è¿”å›æœ€ç»ˆç»“æœã€‚

æ¯”å¦‚ï¼Œæˆ‘ä»¬ç›®å‰æœ‰ä¸‰ç±»chainï¼Œåˆ†åˆ«å¯¹åº”ä¸‰ç§å­¦ç§‘çš„é—®é¢˜è§£ç­”ã€‚æˆ‘ä»¬çš„è¾“å…¥å†…å®¹ä¹Ÿæ˜¯ä¸è¿™ä¸‰ç§å­¦ç§‘å¯¹åº”ï¼Œä½†æ˜¯éšæœºçš„ï¼Œæ¯”å¦‚ç¬¬ä¸€æ¬¡è¾“å…¥æ•°å­¦é—®é¢˜ã€ç¬¬äºŒæ¬¡æœ‰å¯èƒ½æ˜¯å†å²é—®é¢˜... è¿™æ—¶å€™æœŸå¾…çš„æ•ˆæœæ˜¯ï¼šå¯ä»¥æ ¹æ®è¾“å…¥çš„å†…å®¹æ˜¯ä»€ä¹ˆï¼Œè‡ªåŠ¨å°†å…¶åº”ç”¨åˆ°å¯¹åº”çš„å­é“¾ä¸­ã€‚RouterChainå°±ä¸ºæˆ‘ä»¬æä¾›äº†è¿™æ ·ä¸€ç§èƒ½åŠ›ã€‚
![alt text](/public/langchain/chain/3.png)
:::info 
å®ƒä¼šâ¾¸å…ˆå†³å®šå°†è¦ä¼ é€’ä¸‹å»çš„â¼¦é“¾ï¼Œç„¶åæŠŠè¾“â¼Šä¼ é€’ç»™é‚£ä¸ªé“¾ã€‚å¹¶ä¸”åœ¨è®¾ç½®çš„æ—¶å€™éœ€è¦æ³¨æ„ä¸ºå…¶**è®¾ç½®é»˜è®¤chain**ï¼Œä»¥å…¼å®¹è¾“â¼Šå†…å®¹ä¸æ»¡â¾œä»»æ„â¼€é¡¹æ—¶çš„æƒ…å†µã€‚
:::
**RouterChainå›¾ç¤ºï¼š**
![alt text](/public/langchain/chain/4.png)
### 2.6 æ–‡æ¡£é“¾ StuffDocumentsChain(äº†è§£)
StuffDocumentsChain æ˜¯ä¸€ç§æ–‡æ¡£å¤„ç†é“¾ï¼Œå®ƒçš„æ ¸å¿ƒä½œç”¨æ˜¯å°†`å¤šä¸ªæ–‡æ¡£å†…å®¹åˆå¹¶`ï¼ˆâ€œå¡«å……â€æˆ–â€œå¡å…¥â€ï¼‰åˆ°å•ä¸ªæç¤ºï¼ˆpromptï¼‰ä¸­ï¼Œç„¶åä¼ é€’ç»™è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰è¿›è¡Œå¤„ç†ã€‚

**ä½¿ç”¨åœºæ™¯**ï¼šç”±äºæ‰€æœ‰æ–‡æ¡£è¢«å®Œæ•´æ‹¼æ¥ï¼ŒLLMèƒ½åŒæ—¶çœ‹åˆ°å…¨éƒ¨å†…å®¹ï¼Œæ‰€ä»¥é€‚åˆéœ€è¦å…¨å±€ç†è§£çš„ä»»åŠ¡ï¼Œå¦‚æ€»ç»“ã€é—®ç­”ã€å¯¹æ¯”åˆ†æç­‰ã€‚ä½†æ³¨æ„ï¼Œä»…é€‚åˆå¤„ç†`å°‘é‡/ä¸­ç­‰é•¿åº¦æ–‡æ¡£`çš„åœºæ™¯ã€‚

***ä¸¾ä¾‹ï¼š***
```python
#1.å¯¼å…¥ç›¸å…³åŒ…
from langchain.chains import StuffDocumentsChain
from langchain.chains import LLMChain
from langchain.prompts import PromptTemplate
from langchain.document_loaders import PyPDFLoader
from langchain.chat_models import ChatOpenAI
# 2.åŠ è½½PDF
loader = PyPDFLoader("./asset/example/loader.pdf")
#3.å®šä¹‰æç¤ºè¯
prompt_template = """å¯¹ä»¥ä¸‹æ–‡å­—åšç®€æ´çš„æ€»ç»“:
{text}
ç®€æ´çš„æ€»ç»“:"""
# 4.å®šä¹‰æç¤ºè¯æ¨¡ç‰ˆ
prompt = PromptTemplate.from_template(prompt_template)
# 5.å®šä¹‰æ¨¡å‹
llm = ChatOpenAI(model="gpt-4o-mini")
# 6.å®šä¹‰LLMé“¾
llm_chain = LLMChain(llm=llm, prompt=prompt)
# 7.å®šä¹‰æ–‡æ¡£é“¾
stuff_chain = StuffDocumentsChain(
  llm_chain=llm_chain,
  document_variable_name="text", # åœ¨ prompt æ¨¡æ¿ä¸­ï¼Œæ–‡æ¡£å†…å®¹åº”è¯¥ç”¨å“ªä¸ªå˜é‡åè¡¨ç¤º
) #document_variable_name="text" å‘Šè¯‰ StuffDocumentsChain æŠŠåˆå¹¶åçš„æ–‡æ¡£å†…å®¹å¡«å……åˆ° {text}å˜é‡ä¸­"ã€‚

# 8.åŠ è½½pdfæ–‡æ¡£
docs = loader.load()
# 9.æ‰§è¡Œé“¾
res=stuff_chain.invoke(docs)
#print(res)
print(res["output_text"])
```
```
è’‚æ³•Â·æ´›å…‹å“ˆç‰¹æ˜¯ç”µå­æ¸¸æˆã€Šæœ€ç»ˆå¹»æƒ³VIIã€‹åŠå…¶ç›¸å…³ä½œå“ä¸­çš„è™šæ„è§’è‰²ï¼Œç”±é‡æ‘å“²ä¹Ÿè®¾è®¡ã€‚å¥¹æ˜¯ä¸»è§’å…‹åŠ³å¾·çš„é’æ¢…ç«¹é©¬ï¼Œæ‹¥æœ‰å¼ºå¤§çš„æ ¼æ–—æŠ€èƒ½ï¼Œå¹¶åœ¨æ¸¸æˆä¸­æ‰®æ¼”é‡è¦è§’è‰²ã€‚è’‚æ³•åœ¨å¤šä¸ªæ¸¸æˆå’Œåª’ä½“ä¸­å®¢ä¸²ç™»åœºï¼Œå¹¶è¢«è®¤ä¸ºæ˜¯ç”µå­æ¸¸æˆä¸­åšå¼ºã€ç‹¬ç«‹çš„å¥³æ€§è§’è‰²ä»£è¡¨ã€‚å¥¹çš„å½¢è±¡å’Œæ€§æ ¼å—åˆ°å¹¿æ³›èµèª‰ï¼Œæˆä¸ºäº†ç”µå­æ¸¸æˆç•Œçš„æ ‡å¿—æ€§äººç‰©ä¹‹ä¸€ã€‚
```
## 3. åŸºäºLCELæ„å»ºçš„Chainsçš„ç±»å‹
å‰é¢è®²è§£çš„éƒ½æ˜¯Legacy Chainsï¼Œä¸‹é¢çœ‹æœ€æ–°çš„åŸºäºLCELæ„å»ºçš„Chainsã€‚
```
create_sql_query_chain
create_stuff_documents_chain
create_openai_fn_runnable
create_structured_output_runnable
load_query_constructor_runnable
create_history_aware_retriever
create_retrieval_chain
```
### 3.1 create_sql_query_chain
create_sql_query_chainï¼ŒSQLæŸ¥è¯¢é“¾ï¼Œæ˜¯åˆ›å»ºç”ŸæˆSQLæŸ¥è¯¢çš„é“¾ï¼Œç”¨äºå°†`è‡ªç„¶è¯­è¨€`è½¬æ¢æˆ`æ•°æ®åº“çš„SQLæŸ¥è¯¢`ã€‚

***ä¸¾ä¾‹1ï¼š***
è¿™é‡Œä½¿ç”¨MySQLæ•°æ®åº“ï¼Œéœ€è¦å®‰è£…pymysql
> pip install pymysql
```python
from langchain_openai import ChatOpenAI
from langchain.chains.sql_database.query import create_sql_query_chain
from langchain_community.utilities import SQLDatabase
# è¿æ¥ MySQL æ•°æ®åº“
db_user = "root"
db_password = "abc123" #æ ¹æ®è‡ªå·±çš„å¯†ç å¡«å†™
db_host = "127.0.0.1"
db_port = "3306"
db_name = "atguigudb"
# å›ºå®šæ ¼å¼ï¼šmysql+pymysql://ç”¨æˆ·å:å¯†ç @ipåœ°å€:ç«¯å£å·/æ•°æ®åº“å
db = SQLDatabase.from_uri(f"mysql+pymysql://{db_user}:{db_password}@{db_host}:{db_port}/{db_name}")

print("å“ªç§æ•°æ®åº“ï¼š", db.dialect)
print("è·å–æ•°æ®è¡¨ï¼š", db.get_usable_table_names())
# æ‰§è¡ŒæŸ¥è¯¢
res = db.run("SELECT count(*) FROM employees;")
print("æŸ¥è¯¢ç»“æœï¼š", res)

# åˆ›å»ºå¤§æ¨¡å‹å®ä¾‹
llm = ChatOpenAI(model="gpt-4o-mini")
# è°ƒç”¨Chain
chain = create_sql_query_chain(llm=llm, db=db)
# response = chain.invoke({"question": "æ•°æ®è¡¨employeesä¸­å“ªä¸ªå‘˜å·¥å·¥èµ„é«˜ï¼Ÿ"})
# print(response)
# response = chain.invoke({"question": "æŸ¥è¯¢departmentsè¡¨ä¸­ä¸€å…±æœ‰å¤šå°‘ä¸ªéƒ¨é—¨ï¼Ÿ"})
# print(response)
# response = chain.invoke({"question": "æŸ¥è¯¢last_nameå«Kingçš„åŸºæœ¬æƒ…å†µ"})
# print(response)
# # é™åˆ¶ä½¿ç”¨çš„è¡¨
response = chain.invoke({"question": "ä¸€å…±æœ‰å¤šå°‘ä¸ªå‘˜å·¥ï¼Ÿ","table_names_to_use":["employees"]})
print(response)
```
### 3.2 create_stuff_documents_chain(äº†è§£)
create_stuff_documents_chainç”¨äºå°†`å¤šä¸ªæ–‡æ¡£å†…å®¹`åˆå¹¶æˆ`å•ä¸ªé•¿æ–‡æœ¬`çš„é“¾å¼å·¥å…·ï¼Œå¹¶ä¸€æ¬¡æ€§ä¼ é€’ç»™LLMå¤„ç†ï¼ˆè€Œä¸æ˜¯åˆ†å¤šæ¬¡å¤„ç†ï¼‰ã€‚
é€‚åˆåœºæ™¯ï¼š
- ä¿æŒä¸Šä¸‹æ–‡å®Œæ•´ï¼Œé€‚åˆéœ€è¦å…¨å±€ç†è§£æ‰€æœ‰æ–‡æ¡£å†…å®¹çš„ä»»åŠ¡ï¼ˆå¦‚æ€»ç»“ã€é—®ç­”ï¼‰
- é€‚åˆå¤„ç†`å°‘é‡/ä¸­ç­‰é•¿åº¦æ–‡æ¡£`çš„åœºæ™¯ã€‚
***ä¸¾ä¾‹ï¼š***å¤šæ–‡æ¡£æ‘˜è¦

```python
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.documents import Document
# å®šä¹‰æç¤ºè¯æ¨¡æ¿
prompt = PromptTemplate.from_template("""å¦‚ä¸‹æ–‡æ¡£{docs}ä¸­è¯´ï¼Œé¦™è•‰æ˜¯ä»€ä¹ˆé¢œè‰²çš„ï¼Ÿ""")
# åˆ›å»ºé“¾
llm = ChatOpenAI(model="gpt-4o-mini")
chain = create_stuff_documents_chain(llm, prompt, document_variable_name="docs")
# æ–‡æ¡£è¾“å…¥
docs = [
  Document(page_content="è‹¹æœï¼Œå­¦åMalus pumila Mill.ï¼Œåˆ«ç§°è¥¿æ´‹è‹¹æœã€æŸ°ï¼Œå±äºè”·è–‡ç§‘è‹¹æœå±çš„æ¤ç‰©ã€‚è‹¹æœæ˜¯å…¨çƒæœ€å¹¿æ³›ç§æ¤å’Œé”€å”®çš„æ°´æœä¹‹ä¸€ï¼Œå…·æœ‰æ‚ ä¹…çš„æ ½åŸ¹å†å²å’Œå¹¿æ³›çš„åˆ†å¸ƒèŒƒå›´ã€‚è‹¹æœçš„åŸå§‹ç§ç¾¤ä¸»è¦èµ·æºäºä¸­äºšçš„å¤©å±±å±±è„‰é™„è¿‘ï¼Œå°¤å…¶æ˜¯ç°ä»£å“ˆè¨å…‹æ–¯å¦çš„é˜¿æ‹‰æœ¨å›¾åœ°åŒºï¼Œæä¾›äº†æ‰€æœ‰ç°ä»£è‹¹æœå“ç§çš„åŸºå› åº“ã€‚è‹¹æœé€šè¿‡æ—©æœŸçš„è´¸æ˜“è·¯çº¿ï¼Œå¦‚ä¸ç»¸ä¹‹è·¯ï¼Œä»ä¸­äºšå‘å¤–æ‰©æ•£åˆ°å…¨çƒå„åœ°ã€‚"),
  Document(page_content="é¦™è•‰æ˜¯ç™½è‰²çš„æ°´æœï¼Œä¸»è¦äº§è‡ªçƒ­å¸¦åœ°åŒºã€‚"),
  Document(page_content="è“è“æ˜¯è“è‰²çš„æµ†æœï¼Œå«æœ‰æŠ—æ°§åŒ–ç‰©è´¨ã€‚")
]
# æ‰§è¡Œæ‘˜è¦
chain.invoke({"docs": docs})
```
```
'â¾¹è•‰æ˜¯â»©â¾Šçš„â½”æœï¼Œé€šå¸¸åœ¨æˆç†Ÿæ—¶å‘ˆç°æ˜äº®çš„â»©â¾Šã€‚ä½ æåˆ°çš„æè¿°â€œâ½©â¾Šçš„â½”æœâ€å¯èƒ½æ˜¯å¯¹â¾¹è•‰æœªæˆç†ŸçŠ¶æ€çš„è¯¯è§£ã€‚åœ¨æˆç†Ÿé˜¶æ®µï¼Œå®ƒä»¬â¼¤å¤šæ•°æƒ…å†µä¸‹æ˜¯â»©â¾Šçš„ã€‚'
```